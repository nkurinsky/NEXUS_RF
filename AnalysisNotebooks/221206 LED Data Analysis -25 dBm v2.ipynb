{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LED Data: Dec 6,2022 -- 20221206_205042\n",
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import time \n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "\n",
    "sys.path.append('/home/nexus-admin/NEXUS_RF/BackendTools')\n",
    "import PyMKID_USRP_functions as PUf\n",
    "import PyMKID_resolution_functions as Prf\n",
    "import MB_equations as MBe\n",
    "import MB_analysis as MBa\n",
    "import TimestreamHelperFunctions as Thf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/data/USRP_Laser_Data'\n",
    "series   = \"20221206_205042\"\n",
    "\n",
    "sum_file, dly_file, vna_file, nse_files, led_files = Thf.GetFiles(series, \n",
    "                                                        base_path=datapath,\n",
    "                                                        sep_noise_laser=True,\n",
    "                                                        verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in nse_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the MB Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MB Results come from fitting a temperature scan at a specified RF power\n",
    "use_nexus_MBvals = False\n",
    "\n",
    "if use_nexus_MBvals:\n",
    "    ## As measured in NEXUS\n",
    "    MB_fit_vals = np.array([4.24216+9.75e-6, \n",
    "                            0.177  ,\n",
    "                            0.0125 ,\n",
    "                            4.1e7  ]) ## [ F0 [GHz] , Delta [meV] , alpha , Qi0 ]\n",
    "else:\n",
    "    ## As measured on Caltech sister device (https://arxiv.org/pdf/2111.08064.pdf)\n",
    "    MB_fit_vals = np.array([4.24201000, \n",
    "                            0.184     ,\n",
    "                            0.03801   ,\n",
    "                            4.05538e5 ]) ## [ F0 [GHz] , Delta [meV] , alpha , Qi0 ]\n",
    "    \n",
    "## How much attenuation is in the lines before the chip\n",
    "line_atten_dB = 56.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md, charFs, charZs = Thf.UnpackSummary(sum_file, verbose=False)\n",
    "rf_power = md['power']\n",
    "# print(charFs)\n",
    "# print(charZs)\n",
    "print(\"RF Power at USRP:\", rf_power, \"dBm\")\n",
    "\n",
    "## Since I fucked up the acquisition script this business has to be done to fix the arrays\n",
    "charZs[0] = charFs[0]\n",
    "charFs[0] = charFs[-1]\n",
    "\n",
    "for i in np.arange(len(nse_files)):\n",
    "    print(nse_files[i].split(\"/\")[-1].split(\".\")[0],charZs[i])\n",
    "    print(charFs[i].real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LED voltages\n",
    "Determine how many LED timestream files there are and get an array of the LED voltages used for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voltages = np.array([])\n",
    "\n",
    "for k in md.keys():\n",
    "    if 'LaserScan_' in k:\n",
    "        voltages = np.append(voltages, float(int(1000*md[k]['LEDvoltage'][0]))/1000.)\n",
    "\n",
    "n_volts  = len(voltages)\n",
    "n_runs   = len(led_files)\n",
    "print(n_volts, n_runs, \"<-- These should be the same\")\n",
    "print(\"Vmin = \",np.min(voltages), \"V\")\n",
    "print(\"Vmax = \",np.max(voltages), \"V\")\n",
    "print(\"Vstep = \",int((voltages[1]-voltages[0])*1e3), \"mV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some PSD parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PSD hi and lo frequency limits\n",
    "chunk_up_to      = 1e1\n",
    "decimate_down_to = 5e4\n",
    "\n",
    "## Transient period at front of timestream\n",
    "blank_fraction = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the pulse profile\n",
    "This assumes that each laser timestream is acquired with the same AWG settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract the pulse settings, assuming they're all the same\n",
    "for k in md.keys():\n",
    "    if 'LaserScan_' in k:\n",
    "        LED_rate_Hz = md[k]['LEDfreqHz'][0]\n",
    "        lapse_sec   = md[k]['duration'][0]\n",
    "        pulse_w     = md[k]['LEDpulseus'][0]\n",
    "        delay_ms    = md[k]['delayms'][0]\n",
    "        break\n",
    "print(\"Pulse f: \",LED_rate_Hz,\"Hz\")\n",
    "print(\"Pls wdth:\",pulse_w,\"us\")\n",
    "print(\"Duration:\",lapse_sec,\"sec\")\n",
    "print(\"P  delay:\",delay_ms,\"ms\")\n",
    "\n",
    "total_pulses = LED_rate_Hz*lapse_sec\n",
    "\n",
    "time_btw_pulse = 1./LED_rate_Hz\n",
    "num_pulses = int(total_pulses * (1 - blank_fraction))\n",
    "print(\"Total pulse windows:\",total_pulses)\n",
    "print(\"Time between pulse arrival:\",time_btw_pulse,\"sec\")\n",
    "print(\"Number of windows to look at:\",num_pulses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise cleaning to get cleaning coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in np.arange(len(nse_files)):\n",
    "    ## Do the cleaning of the noise file\n",
    "    powers, PSDs, res, timestreams = Thf.CleanPSDs(nse_files[i], vna_file, \n",
    "        PSD_lo_f    = chunk_up_to, \n",
    "        PSD_hi_f    = decimate_down_to, \n",
    "        f_transient = blank_fraction, \n",
    "        charFs      = charFs[i].real, \n",
    "        charZs      = charZs[i],\n",
    "        MBresults   = MB_fit_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick which files to scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_skip = 0 ## How many to skip at beginning\n",
    "files_to_trim = 0 ## How many to cut off at end\n",
    "\n",
    "LED_files = led_files[files_to_skip:n_runs-files_to_trim]\n",
    "Voltages  = voltages[files_to_skip:n_runs-files_to_trim]\n",
    "\n",
    "LED_files = LED_files[Voltages != 3.50]\n",
    "Voltages  = Voltages[ Voltages != 3.50]\n",
    "\n",
    "for i in np.arange(len(LED_files)):\n",
    "    print(LED_files[i],\":\",Voltages[i])\n",
    "\n",
    "PHASE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulse window plotting and removal of bad windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_plots = True\n",
    "\n",
    "## Window selection\n",
    "pretrig_seconds = (delay_ms-0.25)*1e-3\n",
    "p1 = 5 ; p2 = 90\n",
    "\n",
    "## Create dictionaries to store the cut criteria parameters\n",
    "mean_dict = {}\n",
    "sdev_dict = {}\n",
    "maxv_dict = {}\n",
    "\n",
    "## Loop over every file (LED voltage)\n",
    "for pulse_file in LED_files:\n",
    "    print('===================')\n",
    "    print('plotting pulse file:',pulse_file)\n",
    "    print('using VNA file:     ',vna_file)\n",
    "    print('using noise file:   ',nse_files[0])\n",
    "    noise_file = nse_files[0]\n",
    "\n",
    "    ## Determine how much additional decimation to apply\n",
    "    pulse_noise, pulse_info = PUf.unavg_noi(pulse_file)\n",
    "    pulse_fs = 1./pulse_info['sampling period']\n",
    "    pulse_cleaning_decimation = 4 # int(pulse_fs/decimate_down_to)\n",
    "\n",
    "    ## Get the decimated timestream and frequency step\n",
    "    pulse_noise = Prf.average_decimate(pulse_noise,pulse_cleaning_decimation)\n",
    "    pulse_fs   /= pulse_cleaning_decimation\n",
    "    \n",
    "    ## Create a new array of of frequency space with the applied decimation\n",
    "    sampling_rate = pulse_fs\n",
    "    samples_per_pulse = int(time_btw_pulse*sampling_rate)\n",
    "    N = int(samples_per_pulse)-1\n",
    "    T = N/sampling_rate\n",
    "    t,f = Prf.build_t_and_f(N,sampling_rate)\n",
    "    \n",
    "    ## Define the regions where pulses exist\n",
    "    ## =====================================\n",
    "    \n",
    "    ## This defines where (in # of pulse windows) to start looking for pulse windows\n",
    "    pulse_start = int(total_pulses * blank_fraction)\n",
    "    \n",
    "    ## How many samples to shift the pulse window definition\n",
    "    pretrig = int(pretrig_seconds * sampling_rate)\n",
    "    \n",
    "    ## Create an empty array to store our results in\n",
    "    ## This is the average baseline of the three timestreams across all pulse windows\n",
    "    noise_averages = 0 # np.zeros((3),dtype=np.complex128)\n",
    "    \n",
    "    ## Create empty arrays to store values which we will use to perform quality cuts\n",
    "    ## These will have an entry for each pulse window\n",
    "    bl_means = np.array([])#,dtype=np.complex128)\n",
    "    bl_sdevs = np.array([])#,dtype=np.complex128)\n",
    "    pls_maxs = np.array([])#,dtype=np.complex128)\n",
    "    \n",
    "    ## Create plots to store waveforms\n",
    "    if show_plots:\n",
    "        fi0 = plt.figure(pulse_file+\"_a\")\n",
    "        ax0 = fi0.gca()\n",
    "        ax0.set_xlabel(\"Time [ms]\")\n",
    "        ax0.set_ylabel(r\"$\\log_{10}|S_{21}|$\")\n",
    "        if PHASE:\n",
    "            ax0.set_ylabel(r\"$\\arg (S_{21})$\")\n",
    "        ax0.set_title(\".\".join(pulse_file.split(\"/\")[-1].split(\".\")[0:-1]))\n",
    "\n",
    "        fi1 = plt.figure(pulse_file+\"_b\")\n",
    "        ax1 = fi1.gca()\n",
    "        ax1.set_xlabel(r\"$\\Re(S_{21})$\")\n",
    "        ax1.set_ylabel(r\"$\\Im(S_{21})$\")\n",
    "        ax1.set_title(\".\".join(pulse_file.split(\"/\")[-1].split(\".\")[0:-1]))\n",
    "    \n",
    "    ## Start the loop over pulse windows\n",
    "    k=0\n",
    "    for pulse_i in range(pulse_start,int(total_pulses),1):\n",
    "        \n",
    "        ## Define the sample index where this pulse window ends\n",
    "        pulse_i_end = int((pulse_i+1)*samples_per_pulse)\n",
    "        \n",
    "        ## Define the edges of the pulse window\n",
    "        pulse_idx_start = pulse_i_end - N\n",
    "        pulse_idx_end   = pulse_i_end\n",
    "        \n",
    "        ## Grab the timestream in that region and average it\n",
    "        full_pulse_chunk  = pulse_noise[pulse_idx_start:pulse_idx_end,:]\n",
    "        pretrig_pls_chunk = pulse_noise[pulse_idx_start:pulse_idx_start+pretrig,:]\n",
    "        \n",
    "        ## Determine the two quadratures we care about\n",
    "        phase  = np.angle(pretrig_pls_chunk[:,0])\n",
    "        logmag = np.log10(abs(pretrig_pls_chunk[:,0]))\n",
    "        \n",
    "        ## Find the mean, sdev of pre-trigger window and maximum pulse height in full window\n",
    "        if PHASE:\n",
    "            m = np.mean(phase ) ; bl_means = np.append(bl_means,m)\n",
    "            s = np.std( phase ) ; bl_sdevs = np.append(bl_sdevs,s)\n",
    "            x = np.max(np.angle(full_pulse_chunk[:,0])) ; pls_maxs = np.append(pls_maxs,x)\n",
    "        else:\n",
    "            m = np.mean(logmag) ; bl_means = np.append(bl_means,m)\n",
    "            s = np.std( logmag) ; bl_sdevs = np.append(bl_sdevs,s)\n",
    "            x = np.max(np.log10(abs(full_pulse_chunk[:,0]))) ; pls_maxs = np.append(pls_maxs,x)\n",
    "        \n",
    "        ## Keep a running average of the baseline noise in pre-trigger region across all pulse regions\n",
    "        noise_averages += m    \n",
    "        \n",
    "        ## Plot the full pulse window against time\n",
    "        if show_plots:\n",
    "            if PHASE:\n",
    "                ax0.plot(t*1e3,np.angle(full_pulse_chunk[:,0]),alpha=0.25)\n",
    "            else:\n",
    "                ax0.plot(t*1e3,np.log10(abs(full_pulse_chunk[:,0])),alpha=0.25)\n",
    "            ax1.scatter(full_pulse_chunk[:,0].real,full_pulse_chunk[:,0].imag,alpha=0.25)\n",
    "        \n",
    "        ## Increment the good pulse counter\n",
    "        k += 1\n",
    "    \n",
    "    ## Average the baseline mean over every pulse window\n",
    "    noise_averages /= k\n",
    "    \n",
    "    ## Save the cut criteria to our dictionaries\n",
    "    mean_dict[pulse_file] = bl_means\n",
    "    sdev_dict[pulse_file] = bl_sdevs\n",
    "    maxv_dict[pulse_file] = pls_maxs\n",
    "         \n",
    "    ## Draw some lines to mark the pulse window regions\n",
    "    if show_plots:\n",
    "        if PHASE:\n",
    "            ax0.axhline(y=noise_averages,color=\"k\",ls='--')\n",
    "        else:\n",
    "            ax0.axhline(y=noise_averages,color=\"k\",ls='--')\n",
    "        ax0.axvline(x=pretrig_seconds*1e3,color=\"k\",ls=':')\n",
    "    \n",
    "    ## Create plots that inform our cuts\n",
    "    if show_plots:\n",
    "        fi2 = plt.figure(pulse_file+\"_c\")\n",
    "        ax2 = fi2.gca()\n",
    "        ax2.hist(bl_means, \n",
    "             bins=np.arange(\n",
    "                 start = np.min( bl_means ) ,\n",
    "                 stop  = np.max( bl_means ) + 5e-4,\n",
    "                 step  = 5e-4))\n",
    "        ax2.axvline(x=np.percentile(bl_means,p1), color=\"k\",ls='--')\n",
    "        ax2.axvline(x=np.percentile(bl_means,p2), color=\"k\",ls='--')\n",
    "        if PHASE:\n",
    "            ax2.set_xlabel(r\"Pre-trigger BL mean $\\arg(S_{21})$\")\n",
    "        else:\n",
    "            ax2.set_xlabel(r\"Pre-trigger BL mean $\\log_{10}(|S_{21}|)$\")\n",
    "        ax2.set_ylabel(\"Occurences\")\n",
    "        ax2.set_title(\".\".join(pulse_file.split(\"/\")[-1].split(\".\")[0:-1]))\n",
    "\n",
    "        fi3 = plt.figure(pulse_file+\"_d\")\n",
    "        ax3 = fi3.gca()\n",
    "        ax3.hist(bl_sdevs, \n",
    "             bins=np.arange(\n",
    "                 start = np.min( bl_sdevs ) ,\n",
    "                 stop  = np.max( bl_sdevs ) + 1e-5,\n",
    "                 step  = 1e-5))\n",
    "        ax3.axvline(x=np.percentile(bl_sdevs,p1), color=\"k\",ls='--')\n",
    "        ax3.axvline(x=np.percentile(bl_sdevs,p2), color=\"k\",ls='--')\n",
    "        if PHASE:\n",
    "            ax3.set_xlabel(r\"Pre-trigger BL sdev $\\arg(S_{21})$\")\n",
    "        else:\n",
    "            ax3.set_xlabel(r\"Pre-trigger BL sdev $\\log_{10}(|S_{21}|)$\")\n",
    "        ax3.set_ylabel(\"Occurences\")\n",
    "        ax3.set_title(\".\".join(pulse_file.split(\"/\")[-1].split(\".\")[0:-1]))\n",
    "        \n",
    "        fi4 = plt.figure(pulse_file+\"_e\")\n",
    "        ax4 = fi4.gca()\n",
    "        ax4.hist(pls_maxs, \n",
    "             bins=np.arange(\n",
    "                 start = np.min( pls_maxs ) ,\n",
    "                 stop  = np.max( pls_maxs ) + 5e-4 ,\n",
    "                 step  = 5e-4))\n",
    "        ax4.axvline(x=np.percentile(pls_maxs,p1), color=\"k\",ls='--')\n",
    "        ax4.axvline(x=np.percentile(pls_maxs,p2), color=\"k\",ls='--')\n",
    "        if PHASE:\n",
    "            ax4.set_xlabel(r\"Full window maximum $\\arg(S_{21})$\")\n",
    "        else:\n",
    "            ax4.set_xlabel(r\"Full window maximum $\\log_{10}(|S_{21}|)$\")\n",
    "        ax4.set_ylabel(\"Occurences\")\n",
    "        ax4.set_title(\".\".join(pulse_file.split(\"/\")[-1].split(\".\")[0:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a file path and name where cut limits will be stored\n",
    "save_path = \"/\".join(LED_files[0].split(\"/\")[:5])\n",
    "save_name = series + \"_bl_cutvals\" \n",
    "save_key  = series+\"_cuts\"\n",
    "if PHASE:\n",
    "    save_name += \"_phase\" \n",
    "    save_key  += \"_phase\"\n",
    "\n",
    "force_save = True\n",
    "\n",
    "## Check if cuts already exist\n",
    "if ( os.path.exists(os.path.join(save_path,save_name+\".h5\")) ) and not force_save:\n",
    "    cut_df = pd.read_hdf(os.path.join(save_path,save_name+\".h5\"), key=save_key)\n",
    "    save_cuts = False\n",
    "elif ( os.path.exists(os.path.join(save_path,save_name+\".csv\")) ) and not force_save:\n",
    "    cut_df = pd.read_csv(os.path.join(save_path,save_name+\".h5\"))\n",
    "    save_cuts = False\n",
    "else:\n",
    "    save_cuts = True\n",
    "    print(\"Saving new cut definitions to:\",save_name)\n",
    "    \n",
    "    ## Create a pandas dataframe for the cut limits\n",
    "    cut_df = pd.DataFrame(index=LED_files,columns=None)\n",
    "\n",
    "    ## Define the columns we'll use to store cut limits\n",
    "    cut_df[\"sdev_min\"] = np.ones(len(LED_files))\n",
    "    cut_df[\"sdev_max\"] = np.ones(len(LED_files))\n",
    "    cut_df[\"mean_min\"] = np.ones(len(LED_files))\n",
    "    cut_df[\"mean_max\"] = np.ones(len(LED_files))\n",
    "    cut_df[\"wfmx_min\"] = np.array([None] * len(LED_files))\n",
    "    cut_df[\"wfmx_max\"] = np.array([None] * len(LED_files))\n",
    "\n",
    "    ## Now populate each row in the dataframe\n",
    "    ## Noise scan\n",
    "\n",
    "    ## 2.00 V\n",
    "    _i = 0\n",
    "    cut_df[\"mean_min\"].loc[LED_files[_i]] = -1.3175 # np.percentile(mean_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"mean_max\"].loc[LED_files[_i]] = -1.3125 # np.percentile(mean_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"sdev_min\"].loc[LED_files[_i]] =  0.0009 # np.percentile(sdev_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"sdev_max\"].loc[LED_files[_i]] =  0.0011 # np.percentile(sdev_dict[LED_files[_i]],p2)\n",
    "#     cut_df[\"wfmx_min\"].loc[LED_files[_i]] = np.percentile(maxv_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"wfmx_max\"].loc[LED_files[_i]] = -1.3070 # np.percentile(maxv_dict[LED_files[_i]],p2)\n",
    "    \n",
    "    ## 2.25 V --\n",
    "    _i += 1\n",
    "    cut_df[\"mean_min\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"mean_max\"].loc[LED_files[_i]] = -1.3140 # np.percentile(mean_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"sdev_min\"].loc[LED_files[_i]] =  0.0009 # np.percentile(sdev_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"sdev_max\"].loc[LED_files[_i]] =  0.0011 # np.percentile(sdev_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"wfmx_max\"].loc[LED_files[_i]] = -1.3000 # np.percentile(maxv_dict[LED_files[_i]],98)\n",
    "\n",
    "    ## 2.50 V\n",
    "    _i += 1\n",
    "    cut_df[\"mean_min\"].loc[LED_files[_i]] = -1.3170 # np.percentile(mean_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"mean_max\"].loc[LED_files[_i]] = -1.3130 # np.percentile(mean_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"sdev_min\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"sdev_max\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"wfmx_max\"].loc[LED_files[_i]] = np.percentile(maxv_dict[LED_files[_i]],p2)\n",
    "    \n",
    "    ## Noise scan\n",
    "    \n",
    "    ## 2.75 V --\n",
    "    _i += 1\n",
    "    cut_df[\"mean_min\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"mean_max\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"sdev_min\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"sdev_max\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"wfmx_max\"].loc[LED_files[_i]] = np.percentile(maxv_dict[LED_files[_i]],p2)\n",
    "\n",
    "    ## 3.00 V\n",
    "    _i += 1\n",
    "    cut_df[\"mean_min\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"mean_max\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"sdev_min\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"sdev_max\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"wfmx_max\"].loc[LED_files[_i]] = np.percentile(maxv_dict[LED_files[_i]],p2)\n",
    "    \n",
    "    ## 3.25 V --\n",
    "    _i += 1\n",
    "    cut_df[\"mean_min\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"mean_max\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"sdev_min\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"sdev_max\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"wfmx_max\"].loc[LED_files[_i]] = np.percentile(maxv_dict[LED_files[_i]],p2)\n",
    "    \n",
    "    ## Noise scan\n",
    "\n",
    "    ## 3.50 V\n",
    "    _i += 1\n",
    "    cut_df[\"mean_min\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"mean_max\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"sdev_min\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"sdev_max\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"wfmx_max\"].loc[LED_files[_i]] = np.percentile(maxv_dict[LED_files[_i]],p2)\n",
    "    \n",
    "    ## 3.75 V --\n",
    "    _i += 1\n",
    "    cut_df[\"mean_min\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"mean_max\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"sdev_min\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"sdev_max\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"wfmx_max\"].loc[LED_files[_i]] = np.percentile(maxv_dict[LED_files[_i]],p2)\n",
    "    \n",
    "    ## 4.00 V\n",
    "    _i += 1\n",
    "    cut_df[\"mean_min\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"mean_max\"].loc[LED_files[_i]] = np.percentile(mean_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"sdev_min\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p1)\n",
    "    cut_df[\"sdev_max\"].loc[LED_files[_i]] = np.percentile(sdev_dict[LED_files[_i]],p2)\n",
    "    cut_df[\"wfmx_max\"].loc[LED_files[_i]] = np.percentile(maxv_dict[LED_files[_i]],p2)\n",
    "    \n",
    "    if (save_cuts or force_save):\n",
    "        print(\"Saving cuts to file\", os.path.join(save_path,save_name))\n",
    "        cut_df.to_hdf( os.path.join(save_path,save_name+\".h5\") , save_key)\n",
    "        cut_df.to_csv( os.path.join(save_path,save_name+\".csv\"))\n",
    "        \n",
    "cut_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a dictionary that will contain arrays of bad pulse indeces\n",
    "bad_pls_idxs = {}\n",
    "\n",
    "## Loop over every file (LED voltage)\n",
    "for pulse_file in LED_files:\n",
    "    \n",
    "    ## Extract the cut criteria limits\n",
    "    bl_mean_min = cut_df[\"mean_min\"].loc[pulse_file]\n",
    "    bl_mean_max = cut_df[\"mean_max\"].loc[pulse_file]\n",
    "    bl_sdev_min = cut_df[\"sdev_min\"].loc[pulse_file]\n",
    "    bl_sdev_max = cut_df[\"sdev_max\"].loc[pulse_file]\n",
    "    wf_max__min = cut_df[\"wfmx_min\"].loc[pulse_file]\n",
    "    wf_max__max = cut_df[\"wfmx_max\"].loc[pulse_file]\n",
    "    \n",
    "    ## Extract the cut criteria dictionaries\n",
    "    bl_means = mean_dict[pulse_file]\n",
    "    bl_sdevs = sdev_dict[pulse_file]\n",
    "    pls_maxs = maxv_dict[pulse_file]\n",
    "    \n",
    "    ## Create an empty array for the bad pulse indeces\n",
    "    bad_pulses = np.array([])\n",
    "    \n",
    "    ## Loop over pulse windows\n",
    "    for k in np.arange(len(bl_means)):\n",
    "        \n",
    "        ## Check the cuts for baseline mean\n",
    "        if (bl_means[k] < bl_mean_min) or (bl_means[k] > bl_mean_max):\n",
    "            bad_pulses = np.append(bad_pulses, k)\n",
    "            continue\n",
    "            \n",
    "        ## Check the cuts for baseline sdev\n",
    "        if (bl_sdevs[k] < bl_sdev_min) or (bl_sdevs[k] > bl_sdev_max):\n",
    "            bad_pulses = np.append(bad_pulses, k)\n",
    "            continue\n",
    "            \n",
    "        if wf_max__max is not None:\n",
    "            if (pls_maxs[k] > wf_max__max):\n",
    "                bad_pulses = np.append(bad_pulses, k)\n",
    "                continue\n",
    "                \n",
    "        if wf_max__min is not None:\n",
    "            if (pls_maxs[k] < wf_max__min):\n",
    "                bad_pulses = np.append(bad_pulses, k)\n",
    "                continue\n",
    "    \n",
    "    bad_pls_idxs[pulse_file] = bad_pulses\n",
    "    print(pulse_file, \":\", len(bad_pulses), \"bad pulses\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulse cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_plots = True\n",
    "\n",
    "## Options\n",
    "verbose = False \n",
    "\n",
    "## Window selection for pulse-free region\n",
    "window_shift_seconds = 0 # -8.0e-3\n",
    "frac_to_keep = 0.5\n",
    "\n",
    "j = 0\n",
    "for pulse_file in LED_files:\n",
    "    print('===================')\n",
    "    print('cleaning pulse file:',pulse_file)\n",
    "    print('using VNA file:     ',vna_file)\n",
    "    print('using noise file:   ',nse_files[0])\n",
    "    noise_file = nse_files[0]\n",
    "\n",
    "    ## Determine how much additional decimation to apply\n",
    "    pulse_noise, pulse_info = PUf.unavg_noi(pulse_file)\n",
    "    pulse_fs = 1./pulse_info['sampling period']\n",
    "    pulse_cleaning_decimation = int(np.round(pulse_fs/decimate_down_to))\n",
    "\n",
    "    if verbose:\n",
    "        print('loaded pulse data')\n",
    "\n",
    "    ## Get the decimated timestream and frequency step\n",
    "    pulse_noise = Prf.average_decimate(pulse_noise,pulse_cleaning_decimation)\n",
    "    pulse_fs   /= pulse_cleaning_decimation\n",
    "\n",
    "    if verbose:\n",
    "        print('decimated data by ' + str(pulse_cleaning_decimation) + ' to achieve requested upper bound of ' + '{:2e}'.format(decimate_down_to) + ' Hz' )\n",
    "\n",
    "    ## Create a new array of of frequency space with the applied decimation\n",
    "    sampling_rate = pulse_fs\n",
    "    samples_per_pulse = int(time_btw_pulse*sampling_rate)\n",
    "    N = int(frac_to_keep * samples_per_pulse) ## We look at the second half of a pulse window only\n",
    "    T = N/sampling_rate\n",
    "    t,f = Prf.build_t_and_f(N,sampling_rate)\n",
    "    time = 1e3*(time_btw_pulse-t[::-1])\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Sampling rate:\",sampling_rate,\"per sec\")\n",
    "        print(\"Samples per pulse window:\",samples_per_pulse)\n",
    "        print(\"N=:\",N,\"; T=\",T,\";\",np.shape(f))\n",
    "    \n",
    "    ## Define the regions where pulses exist\n",
    "    ## =====================================\n",
    "    \n",
    "    ## This defines where (in # of pulse windows) to start looking for pulses\n",
    "    pulse_start = int(total_pulses * blank_fraction)\n",
    "    if verbose:\n",
    "        print(\"Starting pulse partitioning after\", pulse_start, \"windows (of\",total_pulses,\")\")\n",
    "    \n",
    "    ## How many samples to shift the pulse window definition\n",
    "    window_shift = int(window_shift_seconds * sampling_rate)\n",
    "    if verbose:\n",
    "        print(\"Shifting pulse window by\", window_shift, \"samples\")\n",
    "    \n",
    "    ## Create empty arrays to store our results in\n",
    "    noise_averages = np.zeros((3),dtype=np.complex128)\n",
    "    J_r = np.zeros((N,3)); J_arc = np.zeros((N,3))\n",
    "    \n",
    "    ## Create empty arrays to store values for histograms\n",
    "    bl_means = np.array([],dtype=np.complex128)\n",
    "    bl_sdevs = np.array([])#,dtype=np.complex128)\n",
    "    \n",
    "    ## Create a plot to store waveforms\n",
    "    if show_plots:\n",
    "        fi0 = plt.figure(pulse_file+\"_a\")\n",
    "        ax0 = fi0.gca()\n",
    "        ax0.set_xlabel(\"Time [ms]\")\n",
    "        ax0.set_ylabel(r\"$\\log_{10}|S_{21}|$\")\n",
    "        ax0.set_title(\".\".join(pulse_file.split(\"/\")[-1].split(\".\")[0:-1]))\n",
    "        \n",
    "        fi1 = plt.figure(pulse_file+\"_b\")\n",
    "        ax1 = fi1.gca()\n",
    "        ax1.set_xlabel(r\"$\\Re(S_{21})$\")\n",
    "        ax1.set_ylabel(r\"$\\Im(S_{21})$\")\n",
    "        ax1.set_title(\".\".join(pulse_file.split(\"/\")[-1].split(\".\")[0:-1]))\n",
    "\n",
    "    ## Count how many good pulses there are\n",
    "    n_good_pulses = num_pulses - len(bad_pls_idxs[pulse_file])\n",
    "    \n",
    "    ## Start the loop over pulse windows\n",
    "    k=0\n",
    "    for pulse_i in range(pulse_start,int(total_pulses),1):\n",
    "        \n",
    "        ## Skip the bad pulse windows\n",
    "        if k in bad_pls_idxs[pulse_file]:\n",
    "            ## Increment the counter\n",
    "            k += 1\n",
    "            continue\n",
    "        \n",
    "        ## Define the sample index where this pulse window ends\n",
    "        pulse_i_end = int((pulse_i+1)*samples_per_pulse)\n",
    "        \n",
    "        ## Define the start of the pulse free region (period after pulse, before the next one, where it should be baseline noise)\n",
    "        no_pulse_idx_start = pulse_i_end + window_shift - N \n",
    "        \n",
    "        ## Define the end of the window (where the pulse-free region ends)\n",
    "        no_pulse_idx_end   = pulse_i_end + window_shift\n",
    "        \n",
    "        ## Grab the timestream in that region and average it\n",
    "        no_pulse_chunk = pulse_noise[no_pulse_idx_start:no_pulse_idx_end,:]\n",
    "        \n",
    "        ## Calculate some means and stdevs of this pulse-free timestream\n",
    "        m = np.mean(no_pulse_chunk,axis=0,dtype=np.complex128) ; bl_means = np.append(bl_means,m[0])\n",
    "        \n",
    "        if PHASE:\n",
    "            s = np.std( np.angle(    no_pulse_chunk[:,0])  ) ; bl_sdevs = np.append(bl_sdevs,s)\n",
    "        else:\n",
    "            s = np.std( np.log10(abs(no_pulse_chunk[:,0])) ) ; bl_sdevs = np.append(bl_sdevs,s)\n",
    "        \n",
    "        ## Keep a running average of the noise across all pulse regions\n",
    "        noise_averages += m / n_good_pulses    \n",
    "        \n",
    "        ## Plot the pulse free region against time\n",
    "        if show_plots: # and (k==0):\n",
    "            ax0.plot(time, np.log10(abs(no_pulse_chunk[:,0])),alpha=0.25)\n",
    "            ax1.scatter(no_pulse_chunk[:,0].real,no_pulse_chunk[:,0].imag,alpha=0.25)\n",
    "\n",
    "        ## Convert to the electronics basis and compute the J objects\n",
    "        r_chunk,arc_chunk,_,_= Prf.electronics_basis(no_pulse_chunk)\n",
    "        J_r += abs(Prf.discrete_FT(r_chunk))**2 / n_good_pulses * 2 * T\n",
    "        J_arc += abs(Prf.discrete_FT(arc_chunk))**2 / n_good_pulses * 2 * T\n",
    "        \n",
    "        ## Increment the counter\n",
    "        k += 1\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Searched\",n_good_pulses,\"pulse windows\")\n",
    "        print('used ' + str(n_good_pulses) + ' chunks to find quiescent point')\n",
    "    \n",
    "    if show_plots:\n",
    "        ax0.axhline(y=np.log10(abs(noise_averages[0])),color=\"k\",ls='--')\n",
    "        \n",
    "        fi2 = plt.figure(pulse_file+\"_c\")\n",
    "        ax2 = fi2.gca()\n",
    "        if PHASE:\n",
    "            ax2.hist(np.angle(bl_means))\n",
    "            ax2.set_xlabel(r\"Pre-trigger BL mean $\\arg(S_{21})$\")\n",
    "        else:\n",
    "            ax2.hist(np.log10(abs(bl_means)))\n",
    "            ax2.set_xlabel(r\"Pre-trigger BL mean $\\log_{10}(|S_{21}|)$\")\n",
    "        ax2.set_ylabel(\"Occurences\")\n",
    "        ax2.set_title(\".\".join(pulse_file.split(\"/\")[-1].split(\".\")[0:-1]))\n",
    "        \n",
    "        fi3 = plt.figure(pulse_file+\"_d\")\n",
    "        ax3 = fi3.gca()\n",
    "        if PHASE:\n",
    "            ax3.hist(bl_sdevs)\n",
    "            ax3.set_xlabel(r\"Pre-trigger BL sdev $\\arg(S_{21})$\")\n",
    "        else:\n",
    "            ax3.hist(bl_sdevs)\n",
    "            ax3.set_xlabel(r\"Pre-trigger BL sdev $\\log_{10}(|S_{21}|)$\")\n",
    "        ax3.set_ylabel(\"Occurences\")\n",
    "        ax3.set_title(\".\".join(pulse_file.split(\"/\")[-1].split(\".\")[0:-1]))\n",
    "\n",
    "    ## Pull the two real quantities from the complex timestream averages\n",
    "    radius_averages = abs(noise_averages)\n",
    "    angle_averages  = np.angle(noise_averages)\n",
    "    if verbose:\n",
    "        print(radius_averages)\n",
    "        print(angle_averages)\n",
    "\n",
    "    ## Rotate the timestream by the averange angle, then get the rotated phase timestream\n",
    "    pulse_timestream_rotated = pulse_noise*np.exp(-1j*angle_averages)\n",
    "    angle_timestream = np.angle(pulse_timestream_rotated)\n",
    "\n",
    "    ## Subtract off the average magnitude value and calculate an arc length\n",
    "    radius = abs(pulse_noise) - radius_averages\n",
    "    arc    = angle_timestream*radius_averages\n",
    "\n",
    "    ## Create output containers for the clean timestreams\n",
    "    radius_clean = np.zeros(radius.shape)\n",
    "    arc_clean    = np.zeros(arc.shape)\n",
    "\n",
    "    if verbose:\n",
    "        print('built radius and arc length timestreams given by quiescent point')\n",
    "        print(noise_file)\n",
    "        \n",
    "    ## Pull the dictionary containing cleaning coefficients from the noise timestream\n",
    "    _,data_info = PUf.clean_noi(noise_file[:-3]+'_cleaned.h5')\n",
    "\n",
    "    ## Loop over each tone in the radius timestream\n",
    "    for t in range(radius.shape[1]):\n",
    "        ## Pull the coefficients from the noise cleaning\n",
    "        radius_coefficient = data_info['radius cleaning coefficient'][t]\n",
    "        arc_coefficient    = data_info['arc cleaning coefficient'][t]\n",
    "\n",
    "        ## Clean each tone with the off-resonance tones\n",
    "        if t == 0:\n",
    "            off_tone_idcs = [1,2]\n",
    "        elif t == 1:\n",
    "            off_tone_idcs = [2]\n",
    "        elif t == 2:\n",
    "            off_tone_idcs = [1]\n",
    "\n",
    "\n",
    "        ## Perform the radius cleaning\n",
    "        off_tone_radius = np.mean(radius[:,off_tone_idcs],axis=1,dtype=np.float64)\n",
    "        radius_clean[:,t] = radius[:,t] - radius_coefficient*off_tone_radius\n",
    "\n",
    "        ## Perform the arc length cleaning\n",
    "        off_tone_arc = np.mean(arc[:,off_tone_idcs],axis=1,dtype=np.float64)\n",
    "        arc_clean[:,t] = arc[:,t] - arc_coefficient*off_tone_arc\n",
    "\n",
    "        if verbose: \n",
    "            print('cleaned tone ' + str(t))\n",
    "\n",
    "    ## Subtract off the mean from cleaned radius and arc length timestreams\n",
    "    radius_clean -= np.mean(radius_clean,axis=0,dtype='float64')\n",
    "    arc_clean -= np.mean(arc_clean,axis=0,dtype='float64')\n",
    "    \n",
    "    ## Save the clean timestreams to a file\n",
    "    pulse_noise_clean = Prf.save_clean_timestreams(pulse_file,\\\n",
    "                                                   radius_averages,\\\n",
    "                                                   angle_averages,\\\n",
    "                                                   radius_clean,\\\n",
    "                                                   arc_clean,\\\n",
    "                                                   sampling_rate,\\\n",
    "                                                   timestreams['radius coefficient'],\\\n",
    "                                                   timestreams['arc coefficient'],\\\n",
    "                                                   override=True)\n",
    "\n",
    "    ## Calculate the PSDs for each of the cleaned pulses\n",
    "    \n",
    "    ## Create containers for our output PSDs\n",
    "    J_r_clean = np.zeros((N,3)); J_arc_clean = np.zeros((N,3))\n",
    "    \n",
    "    ## Loop over pulses\n",
    "    k = 0\n",
    "    for pulse_i in range(pulse_start,int(total_pulses),1):\n",
    "        ## Skip the bad pulse windows\n",
    "        if k in bad_pls_idxs[pulse_file]:\n",
    "            ## Increment the counter\n",
    "            k += 1\n",
    "            continue\n",
    "        \n",
    "        ## Define the sample index where this pulse window ends\n",
    "        pulse_i_end = int((pulse_i+1)*samples_per_pulse) \n",
    "        \n",
    "        ## Define the start of the pulse free region (period after pulse, before the next one, where it should be baseline noise)\n",
    "        no_pulse_idx_start = pulse_i_end + window_shift - N \n",
    "        \n",
    "        ## Define the end of the window (where the pulse-free region ends)\n",
    "        no_pulse_idx_end   = pulse_i_end + window_shift\n",
    "        \n",
    "        ## Grab the timestream in that region\n",
    "        no_pulse_chunk = pulse_noise_clean[no_pulse_idx_start:no_pulse_idx_end,:]\n",
    "\n",
    "        ## Convert the pulse-free region to electronics basis\n",
    "        r_chunk,arc_chunk,_,_= Prf.electronics_basis(no_pulse_chunk)\n",
    "        \n",
    "        ## Compute the PSDs\n",
    "        J_r_clean += abs(Prf.discrete_FT(r_chunk))**2 / n_good_pulses * 2 * T\n",
    "        J_arc_clean += abs(Prf.discrete_FT(arc_chunk))**2 / n_good_pulses * 2 * T\n",
    "        \n",
    "        ## Increment the counter\n",
    "        k += 1\n",
    "\n",
    "    ## Trim the output to the positive frequency region only\n",
    "    J_r = J_r[f>=0]; J_r_clean = J_r_clean[f>=0]; J_arc = J_arc[f>=0]; J_arc_clean = J_arc_clean[f>=0]\n",
    "    \n",
    "    ## Every Nth files, show the PSDs\n",
    "    if j % 1 == 0:\n",
    "        print(pulse_file)\n",
    "        fig_0, axes_0 = plt.subplots(2,3,sharex=True,sharey='row',figsize=(5*3,10))\n",
    "        \n",
    "        Prf.plot_PSDs(f[f>0],J_r,J_arc,pulse_file,\\\n",
    "                      ['radius','arc length'],units=['ADCu','ADCu'],savefig='electronics',\\\n",
    "                      data_freqs=pulse_info['search freqs'],\\\n",
    "                      P_1_clean=J_r_clean,P_2_clean=J_arc_clean,\\\n",
    "                      fig_0=fig_0,axes_0=axes_0)\n",
    "\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulse averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "fraction_to_keep = 0.5 # 1.0 # 0.5 # (5.0/12.5) # 1.0\n",
    "window_shift_seconds = 0 # 5.0e-3\n",
    "verbose = False\n",
    "\n",
    "j = 0 \n",
    "for pulse_file in LED_files:\n",
    "    \n",
    "    ## Get the VNA data for this set of runs\n",
    "    f,z = PUf.read_vna(vna_file)\n",
    "\n",
    "    print('===================')\n",
    "    print('averaging pulse file: ' + pulse_file)\n",
    "\n",
    "    ## Load the clean pulse data\n",
    "    clean_pulse_file = pulse_file[:-3] + '_cleaned.h5'\n",
    "    pulse_noise_clean,data_info = PUf.clean_noi(clean_pulse_file)\n",
    "    if verbose: \n",
    "        print('loaded clean pulse data')        \n",
    "        print('sampling_rate: ' + str(data_info['sampling_rate']))\n",
    "    \n",
    "    ## Determine how many samples are in each pulse window\n",
    "    samples_per_pulse = data_info['sampling_rate'] * time_btw_pulse\n",
    "\n",
    "    ## Do extra decimation if needed (1 = no decimation) \n",
    "    decimation = 1\n",
    "    time = Prf.average_decimate(pulse_info['time'],decimation)\n",
    "    pulse_noise_clean = Prf.average_decimate(pulse_noise_clean,decimation)\n",
    "    \n",
    "    ## Update the samples per window and sampling rate with new decimation\n",
    "    samples_per_pulse_decimated = int(samples_per_pulse / decimation)\n",
    "    sampling_rate = data_info['sampling_rate'] / decimation\n",
    "    if verbose:\n",
    "        print('further decimation by ' + str(decimation) + ' complete')\n",
    "\n",
    "    ## Create a container to store our average pulse in complex S21 for this file\n",
    "    pulse_avg    = np.zeros(int(samples_per_pulse_decimated*fraction_to_keep),dtype=np.complex128)\n",
    "    \n",
    "    ## Determine how many samples to shift the window by\n",
    "    window_shift = int(window_shift_seconds*sampling_rate)\n",
    "    \n",
    "    ## Identify the first pulse window after the transient period\n",
    "    pulse_start  = int(total_pulses * blank_fraction)\n",
    "    \n",
    "    ## Count how many good pulses there are in this file\n",
    "    n_good_pulses = num_pulses - len(bad_pls_idxs[pulse_file])\n",
    "    \n",
    "    ## Start the loop over pulse windows\n",
    "    k=0\n",
    "    for pulse_i in range(pulse_start,int(total_pulses),1):\n",
    "        \n",
    "        ## Skip the bad pulse windows\n",
    "        if k in bad_pls_idxs[pulse_file]:\n",
    "            ## Increment the counter\n",
    "            k += 1\n",
    "            continue\n",
    "            \n",
    "        ## Define the sample index where this pulse window ends\n",
    "        pulse_idx_start = int((pulse_i  )*samples_per_pulse_decimated) + window_shift\n",
    "        pulse_idx_end   = int(round((pulse_i+fraction_to_keep)*samples_per_pulse_decimated,0)) + window_shift\n",
    "        \n",
    "        ## Create a list of indeces corresponding to the samples in this pulse window\n",
    "        pulse_idx_list = np.arange(pulse_idx_start,pulse_idx_end,1,dtype=int)\n",
    "        \n",
    "        ## Average the pulses in each good window\n",
    "        pulse_avg += pulse_noise_clean[pulse_idx_list,0] / n_good_pulses\n",
    "        \n",
    "        ## Increment the counter\n",
    "        k += 1\n",
    "    \n",
    "    ## Create a figure in complex S21 to show VNA, full timestream, and average pulse\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    plt.suptitle(pulse_file.split(\"/\")[-1])\n",
    "    axs[0].set_xlabel(r\"$\\Re(S_{21})$\")\n",
    "    axs[0].set_ylabel(r\"$\\Im(S_{21})$\")\n",
    "    axs[1].set_xlabel(\"Time [ms]\")\n",
    "    axs[1].set_ylabel(r\"$\\log10 |S_{21}|$\")\n",
    "    \n",
    "    axs[0].plot(pulse_noise_clean[:,0].real,pulse_noise_clean[:,0].imag,ls='',marker='.',alpha=0.1,color='grey')\n",
    "    axs[0].plot(pulse_avg.real,pulse_avg.imag,color='C'+str(j % 10),ls='-',marker='.')\n",
    "    axs[0].plot(z.real,z.imag,color='k',ls='-',marker='.',alpha=1.00)\n",
    "    \n",
    "    axs[1].plot(time[pulse_idx_list,0]*1e3,np.log10(abs(pulse_noise_clean[pulse_idx_list,0])))\n",
    "    axs[1].plot(time[pulse_idx_list,0]*1e3,np.log10(abs(pulse_avg)))\n",
    "    \n",
    "    width = 50 * np.std(pulse_noise_clean[:,0].real)\n",
    "    x_c = np.mean(pulse_avg.real)\n",
    "    y_c = np.mean(pulse_avg.imag)\n",
    "    axs[0].set_xlim([x_c - width/2., x_c + width/2.])\n",
    "    axs[0].set_ylim([y_c - width/2., y_c + width/2.])\n",
    "    axs[0].set_aspect('equal','box')\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "        \n",
    "    print('Used ' + str(n_good_pulses) + ' pulses to average')\n",
    "    with h5py.File(clean_pulse_file, \"a\") as fyle:\n",
    "        if 'pulse_shape' in fyle.keys():\n",
    "            del fyle['pulse_shape']\n",
    "            print('deleted an old pulse shape')\n",
    "        fyle.create_dataset('pulse_shape',data = np.asarray(pulse_avg))\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulse rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "time_window_range = fraction_to_keep * time_btw_pulse *1e6\n",
    "time_window = np.arange(0,time_window_range,1/sampling_rate*1e6)#[:-1]\n",
    "\n",
    "tw_min =  8000 \n",
    "tw_max = 10000 \n",
    "\n",
    "AWF_string = str(int(10*pulse_w)/10) + \" us\"\n",
    "title_1    = 'power ' + str(rf_power) + '; AWF ' + AWF_string + ': pulses in S21'\n",
    "title_1p5  = 'power ' + str(rf_power) + '; AWF ' + AWF_string + ': pulses in S21, zoomed in'\n",
    "title_1p75 = 'alignment of pulses using largest pulse (blue)' \n",
    "title_2    = 'S_21 pulse height along pulse alignment axis'\n",
    "\n",
    "for pulse_file in LED_files[::-1]:\n",
    "    print('===================')\n",
    "    print('cleaning pulse file:',pulse_file)\n",
    "    print('using VNA file:     ',vna_file)\n",
    "    print('using summary file: ',sum_file)\n",
    "    char_file = sum_file\n",
    "\n",
    "    clean_pulse_file = pulse_file[:-3] + '_cleaned.h5'\n",
    "    with h5py.File(clean_pulse_file, \"r\") as fyle:\n",
    "        pulse_avg = np.array(fyle[\"pulse_shape\"],dtype=np.complex128)\n",
    "        pulse_timestream = np.array(fyle[\"cleaned_data\"],dtype=np.complex128)\n",
    "\n",
    "    ## Pull the readout fequency and the VNA data\n",
    "    readout_f = charFs[1]\n",
    "    f,z = PUf.read_vna(vna_file)\n",
    "\n",
    "    ## Get the timestreams in the resonator basis\n",
    "    df_f, d1_Q, _, _ = Prf.resonator_basis(pulse_avg,readout_f*1e-3,f*1e-3,z,charFs*1e-3,charZs)#,plot_title='power ' + power_directories[j][:-1] + ' AWF ' + AWF_string)\n",
    "    df_f_timestream, d1_Q_timestream, _, _ = Prf.resonator_basis(pulse_timestream[:,0],readout_f*1e-3,f*1e-3,z,charFs*1e-3,charZs)\n",
    "    \n",
    "    ## Get the timestreams in the quasiparticle basis\n",
    "    dk1, dk2 =                       Prf.quasiparticle_basis(df_f, d1_Q,\n",
    "                                                             data_T     = 10.0e-3, \n",
    "                                                             MB_results = MB_fit_vals,\n",
    "                                                             readout_f  = readout_f*1e-3)\n",
    "    dk1_timestream, dk2_timestream = Prf.quasiparticle_basis(df_f_timestream, d1_Q_timestream,\n",
    "                                                             data_T     = 10.0e-3, \n",
    "                                                             MB_results = MB_fit_vals,\n",
    "                                                             readout_f  = readout_f*1e-3)\n",
    "    \n",
    "    ## Get the average pulse, baseline subtracted\n",
    "    pulse_avg_mb = pulse_avg - np.mean(pulse_avg[-5:],dtype=np.complex128)\n",
    "    std          = np.std(abs(pulse_avg_mb[-5:]),dtype=np.complex128)\n",
    "    \n",
    "    ## Find the average angle of the timestream in a fixed window\n",
    "    average_angle       = np.mean(np.angle(pulse_avg_mb[np.logical_and(time_window>tw_min,time_window<tw_max)]))\n",
    "    \n",
    "    ## Extract the baseline subtracted pulse timestream\n",
    "    pulse_timestream_mb = pulse_timestream[:,0] - np.mean(pulse_avg[-5:],dtype=np.complex128)\n",
    "\n",
    "    ## Apply a rotation by the average angle to the average pulse and timestream\n",
    "    pulse_avg_rotated        = pulse_avg_mb * np.exp(-1j*average_angle)\n",
    "    pulse_timestream_rotated = pulse_timestream_mb * np.exp(-1j*average_angle)\n",
    "    \n",
    "    ## Determine a template to use in a praticular basis\n",
    "    template_eb = pulse_avg_rotated.real\n",
    "    noise_eb = pulse_timestream_rotated.real\n",
    "    ylbl_df  = r\"$\\Re (S_{21})$\"\n",
    "    \n",
    "    template_df = df_f - np.mean(df_f[:20])\n",
    "    noise_df = df_f_timestream - np.mean(df_f[:20])\n",
    "    ylbl_df  = r\"$\\delta f/f$\"\n",
    "    \n",
    "    template_dk2 = dk2 - np.mean(dk2[:20])\n",
    "    noise_dk2 = dk2_timestream - np.mean(dk2[:20])\n",
    "    ylbl_dk2  = r\"$\\delta \\kappa_2$ [$\\mu$m$^{-3}$]\"\n",
    "    \n",
    "    template = template_df\n",
    "    noise = noise_df\n",
    "    ylbl  = ylbl_df\n",
    "\n",
    "    ## Write the template pulse and the timestreams in different basis to a cleaned pulse file\n",
    "    with h5py.File(clean_pulse_file, \"a\") as fyle:\n",
    "        print(\"Saving clean pulse file:\",clean_pulse_file)\n",
    "        if 'df_f_template' in fyle.keys():\n",
    "            del fyle['df_f_template']\n",
    "        if 'df_f_pulse_noise' in fyle.keys():\n",
    "            del fyle['df_f_pulse_noise']\n",
    "        fyle.create_dataset('df_f_template',   data = np.asarray(template))\n",
    "        fyle.create_dataset('df_f_pulse_noise',data = np.asarray(noise))\n",
    "    \n",
    "    ## If this is the first LED file (largest voltage)\n",
    "    label_c = 'characterization data' if i == 0 else None\n",
    "    label_V = 'VNA' if i == 0 else None\n",
    "    label_p = 'pulse data ' if i == 0 else None\n",
    "\n",
    "    ## Create the VNA-style plot with characterization data and average pulse timestreams\n",
    "    plt.figure(title_1)\n",
    "    plt.plot(pulse_avg.real,pulse_avg.imag,ls='-',marker='.',markersize=5,color='C'+str(i%10))\n",
    "    plt.plot(z.real,z.imag,color='k',label=label_V)\n",
    "    plt.plot(charZs.real,charZs.imag,marker='*',markersize=10,ls='',label=label_c,zorder=-5*i+200)\n",
    "    plt.axhline(0,color='grey')\n",
    "    plt.axvline(0,color='grey')\n",
    "    plt.title(title_1)\n",
    "    width = np.std(pulse_avg.real) * 8e3 # * 8e3 \n",
    "    x_c = np.mean(pulse_avg.real)\n",
    "    y_c = np.mean(pulse_avg.imag)\n",
    "    plt.axis([x_c - width/2., x_c + width/2., y_c-width/2., y_c+width/2.])\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal','box')\n",
    "    plt.legend()\n",
    "\n",
    "    ## Create the zoomed-in VNA-style plot with characterization data and pulse timestream\n",
    "    plt.figure(title_1p5)\n",
    "    plt.plot(pulse_avg.real,pulse_avg.imag,ls='-',marker='.',markersize=5,color='C'+str(i%10),label=label_p,zorder=-5*i+200)\n",
    "    plt.plot(z.real,z.imag,color='k',label=label_V)\n",
    "    plt.plot(charZs.real,charZs.imag,marker='*',markersize=10,ls='',label=label_c,zorder=-5*i+200)\n",
    "    \n",
    "    if i == 0:\n",
    "        width = 100 * np.std(pulse_avg.real)\n",
    "        x_c = np.mean(pulse_avg.real)\n",
    "        y_c = np.mean(pulse_avg.imag)\n",
    "        plt.axis([x_c - width/2., x_c + width/2., y_c-width/2., y_c+width/2.])\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.title(title_1p5)\n",
    "\n",
    "    ## Draw the rotated pulse plot\n",
    "    plt.figure(title_1p75)\n",
    "    plt.plot(pulse_avg_rotated.real,pulse_avg_rotated.imag,ls='-',marker='.',markersize=5,color='C'+str(i%10))\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', 'box')\n",
    "    plt.title(title_1p75)\n",
    "    \n",
    "    ## Select which pulse average to plot - use the one selected as the template\n",
    "    pulse_avg_plot = template\n",
    "    \n",
    "    ## Create a figure of the pulses in the rotated basis\n",
    "    plt.figure(title_2)\n",
    "    plt.plot(time_window,pulse_avg_plot,ls='-',marker='.',markersize=5,color='C'+str(i))\n",
    "    plt.xlabel('microseconds')\n",
    "    plt.ylabel(ylbl)\n",
    "    plt.title(title_2)\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "plt.figure(title_1p5)\n",
    "\n",
    "ai = 1\n",
    "for f in nse_files:\n",
    "    ## Get the noise timestream and average\n",
    "    frequencies_scanned, noise_mean_scanned = PUf.avg_noi(f,time_threshold=30.0*blank_fraction)\n",
    "    ## Draw the points\n",
    "    plt.plot(noise_mean_scanned[0].real,noise_mean_scanned[0].imag,marker='*',markersize=10,markeredgecolor='k',ls='None',color='y',zorder=-5*i+200,alpha=ai*.2,label=\"Noise Averages\")\n",
    "    ai += 1\n",
    "    ## Draw an arrow from the last one\n",
    "\n",
    "## Plot the characterization data\n",
    "for ii in np.arange(len(charZs)):\n",
    "    plt.scatter(charZs[ii].real,charZs[ii].imag,marker='*',ls='None',label=\"Characterization Data\",zorder=-5*i+200,c='g',alpha=(ii+1)*0.2)\n",
    "    \n",
    "for ii in np.arange(len(charZs)-1):\n",
    "    x0 = charZs[ii  ].real; y0 = charZs[ii  ].imag\n",
    "    x1 = charZs[ii+1].real; y1 = charZs[ii+1].imag\n",
    "    dx = x1-x0\n",
    "    dy = y1-y0\n",
    "    \n",
    "    for iii in np.arange(len(x0)):\n",
    "        plt.arrow(x0[iii],y0[iii],dx[iii],dy[iii],length_includes_head=True,color='g',alpha=(ii+1)*0.2,width=1e-5,head_width=1e-4)\n",
    "    \n",
    "plt.legend()\n",
    "    \n",
    "# directory = \"/data/ProcessedOutputs/out\"+series\n",
    "# plt.figure(title_1)\n",
    "# plt.savefig(directory + 'VNA_char_pulse_S21.png',dpi=300,facecolor='white',transparent=False)\n",
    "# plt.figure(title_1p5)\n",
    "# plt.savefig(directory + 'VNA_char_pulse_S21_zoomed_in.png',dpi=300,facecolor='white',transparent=False)\n",
    "# plt.figure(title_1p75)\n",
    "# plt.savefig(directory + 'pulse_alignment.png',dpi=300,facecolor='white',transparent=False)\n",
    "# plt.figure(title_2)\n",
    "# plt.savefig(directory +'timestream_aligned',dpi=300,facecolor='white',transparent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimal Filter code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OF Window parameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of seconds by which to shift the window when calculating J\n",
    "window_shift_J = 0 # -8.0e-3 # -10e-6 #\n",
    "\n",
    "## Define a maximum frequency for the fourier-space mask\n",
    "f_max = 1e4 ## Hz maximum freq in fourier space\n",
    "\n",
    "## Create titles for the plots\n",
    "title      = 'readout power ' + str(rf_power) + ': '\n",
    "\n",
    "## Create a colormap for plotting different LED powers\n",
    "cmap   = plt.get_cmap('OrRd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the signal template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_fit_as_template = False\n",
    "\n",
    "## Pick the highest LED voltage data to use as signal template\n",
    "pls_file_template = LED_files[-1]\n",
    "print(\"Using file:\",pls_file_template,\"as pulse template\")\n",
    "\n",
    "## Find the clean pulse file, use the last one in the set that's been analyzed so far\n",
    "clean_pulse_file = pls_file_template[:-3] + '_cleaned.h5'\n",
    "\n",
    "## Open the cleaned data and pull the data sampling rate, pulse template, and pulse noise\n",
    "with h5py.File(clean_pulse_file, \"r\") as fyle:\n",
    "    sampling_rate = np.array(fyle['sampling_rate'])\n",
    "    pulse_avg_df  = np.array(fyle[\"df_f_template\"])\n",
    "#     pulse_avg_dk2 = np.array(fyle[\"dk2_template\"])\n",
    "pulse_avg = pulse_avg_df\n",
    "\n",
    "## Determine a window size equivalent to the full pulse template window\n",
    "N = len(pulse_avg)\n",
    "print(N, \"samples per window\")\n",
    "\n",
    "## Determine total period of the template and create a time-domain array and a freq-domain array\n",
    "T = N/sampling_rate\n",
    "time, f = Prf.build_t_and_f(N,sampling_rate)\n",
    "\n",
    "## Define an offset function to recenter the pulse\n",
    "t_offset = lambda N: int( (delay_ms*1e-3) * sampling_rate)\n",
    "\n",
    "## Define an exponential function\n",
    "exponential = lambda x, A, tau: np.heaviside(x-time[t_offset(N)],0.5) * A * np.exp(-1*(x-time[t_offset(N)])/tau)\n",
    "dbl_expA    = lambda x, A, t1, t2: np.heaviside(x-time[t_offset(N)],0.5) * A * ( np.exp(-1*(x-time[t_offset(N)])/t1) + np.exp(-1*(x-time[t_offset(N)])/t2) )\n",
    "\n",
    "## Fit the average pulse to an exponential\n",
    "amp_guess   = 5.0e0 # 5.0e-7\n",
    "popt, pcov  = curve_fit(exponential,time,pulse_avg,p0=[amp_guess,       1.24e-3])\n",
    "popt2,pcov2 = curve_fit(dbl_expA,time,pulse_avg   ,p0=[amp_guess,       1.24e-3/5.,1.24e-3*5.])\n",
    "\n",
    "## Calculate the best fit curve for the average pulse\n",
    "pulse_fit  = exponential(time,*popt)\n",
    "pulse_fit2 = dbl_expA(time,*popt2)\n",
    "    \n",
    "## Numerically integrate the fit, then FT it\n",
    "if use_fit_as_template:   \n",
    "    A = np.trapz(pulse_fit,dx = time[1]-time[0])\n",
    "    s = Prf.discrete_FT(pulse_fit)\n",
    "else:\n",
    "    A = np.trapz(pulse_avg,dx = time[1]-time[0])\n",
    "    s = Prf.discrete_FT(pulse_avg)\n",
    "\n",
    "## Define a mask for evaluating fourier space components\n",
    "f_mask = np.logical_and(f <= f_max, f >= -1*f_max)\n",
    "N_mask = len(f[f_mask])\n",
    "f_plot = np.logical_and(f > 0, f <= f_max)\n",
    "new_fs = max(f[f_mask])\n",
    "\n",
    "## Get the magnitude of s^2 for the masked region\n",
    "S_mag = abs(s[f_mask]**2)\n",
    "\n",
    "## Create a plot to store the template waveform and best fit\n",
    "f1p5  = plt.figure()\n",
    "ax1p5 = f1p5.gca()\n",
    "ax1p5.plot(time*1e3,pulse_fit, 'C7',linewidth=3,label='time constant: {:.2e}ms'.format(popt[-1]*1e3), ls='--' )\n",
    "ax1p5.plot(time*1e3,pulse_fit2,'k' ,linewidth=1,label='Equal weights\\n'+r'$\\tau_1=$ {:.2e}ms'.format(popt2[-2]*1e3)+\"\\n\"+r'$\\tau_2=$ {:.2e}ms'.format(popt2[-1]*1e3))\n",
    "ax1p5.plot(time*1e3,pulse_avg, label=\"Average pulse\")\n",
    "ax1p5.axhline(y=0,color='r',ls='--')\n",
    "ax1p5.set_title(title + 'signal pulse timestream and fit')\n",
    "ax1p5.set_xlabel(\"Time [ms]\")\n",
    "ax1p5.set_ylabel(r\"Frequency Shift $\\delta f / f$\")\n",
    "ax1p5.set_ylabel(r\"Dissipation Shift $\\delta \\kappa_2$ [$\\mu$m$^{-3}$]\")\n",
    "plt.legend()\n",
    "\n",
    "f1p7  = plt.figure()\n",
    "ax1p7 = f1p7.gca()\n",
    "ax1p7.plot(time*1e3,pulse_fit -pulse_avg,'C7',linewidth=3,label=r'$\\tau=$ {:.2e}ms'.format(popt[-1]*1e3) , ls='--' )\n",
    "ax1p7.plot(time*1e3,pulse_fit2-pulse_avg,'k' ,linewidth=1,label='Equal weights\\n'+r'$\\tau_1=$ {:.2e}ms'.format(popt2[-2]*1e3)+\"\\n\"+r'$\\tau_2=$ {:.2e}ms'.format(popt2[-1]*1e3))\n",
    "ax1p7.axhline(y=0,color='r',ls='--')\n",
    "ax1p7.set_title(title + 'fit residuals')\n",
    "ax1p7.set_xlabel(\"Time [ms]\")\n",
    "ax1p7.set_ylabel(\"Fit residual\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the noise template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pick the lowest LED voltage data to use as noise template\n",
    "nse_file_template = LED_files[0]\n",
    "print(\"Using file:\",nse_file_template,\"to characterize noise\")\n",
    "\n",
    "## Find the clean noise file, use the last one in the set that's been analyzed so far\n",
    "clean_noise_file = nse_file_template[:-3] + '_cleaned.h5'\n",
    "\n",
    "## Open the cleaned data and pull the data sampling rate, pulse template, and pulse noise\n",
    "with h5py.File(clean_noise_file, \"r\") as fyle:\n",
    "    sampling_rate = np.array(fyle['sampling_rate'])          \n",
    "    pulse_noise   = np.array(fyle[\"df_f_pulse_noise\"])\n",
    "\n",
    "## Determine total period of the template and create a time-domain array and a freq-domain array\n",
    "T = N/sampling_rate\n",
    "time, f = Prf.build_t_and_f(N,sampling_rate)\n",
    "\n",
    "## Determine how many samples to shift the window when calculating J\n",
    "samples_per_pulse  = sampling_rate*time_btw_pulse\n",
    "window_shift_J_idx = int(window_shift_J*sampling_rate)\n",
    "    \n",
    "## Create a container to store J in temporarily\n",
    "J = np.zeros(N)\n",
    "    \n",
    "## Count how many good pulses there are in this file\n",
    "n_good_pulses = num_pulses - len(bad_pls_idxs[pulse_file])\n",
    "\n",
    "## Loop over all the pulse windows in the file\n",
    "## We want to skip the windows cut out when finding noise free region\n",
    "k = 0\n",
    "for pulse_i in range(pulse_start,int(total_pulses),1):\n",
    "\n",
    "    ## Skip the bad pulse windows\n",
    "    if k in bad_pls_idxs[pulse_file]:\n",
    "        ## Increment the counter\n",
    "        k += 1\n",
    "        continue\n",
    "\n",
    "    ## Find the index for the end of this pulse window\n",
    "    pulse_i_end = int((pulse_i+1)*samples_per_pulse) \n",
    "\n",
    "    ## Apply the window shift and an array of samples for the window timestream points\n",
    "    ## Are we really trying to find a pulse free region? seems like it\n",
    "    no_pulse_idx_start = pulse_i_end + window_shift_J_idx - N\n",
    "    no_pulse_idx_end   = pulse_i_end + window_shift_J_idx\n",
    "    no_pulse_idx_list  = np.arange(no_pulse_idx_start,no_pulse_idx_end,1,dtype=int)\n",
    "    no_pulse_noise_i   = pulse_noise[no_pulse_idx_list]\n",
    "\n",
    "    ## Caclulate the average J for this region\n",
    "    J += abs(Prf.discrete_FT(no_pulse_noise_i))**2 / n_good_pulses * 2 * T\n",
    "\n",
    "    ## Increment the counter\n",
    "    k += 1\n",
    "    \n",
    "## Determine the average J for plotting\n",
    "J_avg = np.mean(J)\n",
    "\n",
    "## Calculate the denominator for the optimal filter\n",
    "denominator = np.sum(abs(s[f_mask])**2/J[f_mask])\n",
    "\n",
    "## Calculate the baseline resolution\n",
    "b7_res = np.sqrt(((2*T*denominator)**-1))\n",
    "print(\"Baseline resolution:\", b7_res)\n",
    "\n",
    "## Plot the J we'll use for optimal filtering\n",
    "f2p0  = plt.figure()\n",
    "ax2p0 = f2p0.gca()\n",
    "plt.plot(f[f_plot],J[f_plot],zorder=-5*j+5,color='k')\n",
    "ax2p0.set_title(title + 'noise frequeny domain')\n",
    "ax2p0.set_xlabel(\"Frequency [Hz]\")\n",
    "ax2p0.set_ylabel(r\"$J$\")\n",
    "ax2p0.set_xscale('log')\n",
    "ax2p0.set_yscale('log')\n",
    "ax2p0.set_ylim([5e-2*J_avg,5e2*J_avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "verbose = False\n",
    "\n",
    "## Create titles for the plots\n",
    "title      = 'readout power ' + str(rf_power) + ': '\n",
    "title_1    = title + 'signal template'\n",
    "title_2    = title + 'noise power spectral density'\n",
    "title_2    = 'noise power spectral densities'\n",
    "title_2p2  = 'noise power spectral densities at lowest F'\n",
    "title_2p1  = 'examples of V in time'\n",
    "title_2p5  = 'index of IFFT with peak value'\n",
    "title_3    = title + 'histogram of pulse heights'\n",
    "title_3p5  = title + 'cdf of pulse heights'\n",
    "title_4    = title + 'sigma vs mu'\n",
    "\n",
    "## Something to do about time offset between pulse window and singal template\n",
    "offset_exponent = np.zeros((N_mask,N_mask),dtype=np.complex128)\n",
    "time_ds = np.linspace(0,(N_mask-2)/(2*new_fs),N_mask)\n",
    "print((N_mask-1)/(2*new_fs))\n",
    "for j in range(N_mask):\n",
    "    offset_exponent[j,:] = np.exp(1j*2*np.pi*f[f_mask][j]*time_ds)\n",
    "\n",
    "for j in range(N_mask):\n",
    "    for k in range(N_mask):\n",
    "        if abs(offset_exponent[j,k].real) < 1e-10:\n",
    "            offset_exponent[j,k] = 1j*offset_exponent[j,k].imag\n",
    "        if abs(offset_exponent[j,k].imag) < 1e-10:\n",
    "            offset_exponent[j,k] = offset_exponent[j,k].real\n",
    "\n",
    "## Containers for ...\n",
    "mu    = np.zeros(N_mask)\n",
    "sigma = np.zeros(N_mask)\n",
    "\n",
    "## Create containers to hold the means and standard deviations for the pulse height distribution\n",
    "## for each of the pulse files\n",
    "mus    = []\n",
    "sigmas = []\n",
    "J_at_min_f = np.array([])\n",
    "\n",
    "## Start a loop over pulse files\n",
    "j = 0\n",
    "for pulse_file in LED_files[::-1]:\n",
    "    if verbose: \n",
    "        print('=====================')\n",
    "        print('analyzing data file: ' + pulse_file, \"VLED=\",Voltages[::-1][i])\n",
    "\n",
    "    color = cmap( (Voltages[::-1][j]-1.5) / (np.max(Voltages)-1.5) ) # 'C'+str(j%10)\n",
    "    \n",
    "    ## Pull the average pulse and pulse PSDs from the cleaned pulse data file\n",
    "    clean_pulse_file = pulse_file[:-3] + '_cleaned.h5'\n",
    "    with h5py.File(clean_pulse_file, \"r\") as fyle:\n",
    "        pulse_avg   = np.array(fyle[\"df_f_template\"])            \n",
    "        pulse_noise = np.array(fyle[\"df_f_pulse_noise\"])\n",
    "\n",
    "    ## Recenter the average pulse\n",
    "    pulse_recentered = pulse_avg # np.concatenate((pulse_avg[t_offset(N):],pulse_avg[:t_offset(N)]))\n",
    "    \n",
    "    ## Fit the average pulse to an exponential\n",
    "    popt,pcov = curve_fit(exponential,time,pulse_recentered,p0=[1.2e-4,50e-6])\n",
    "    \n",
    "    ## Calculate the best fit curve for the average pulse\n",
    "    pulse_fit = exponential(time,*popt)\n",
    "    \n",
    "    ## Get the frequency space of the average pulse\n",
    "    s_temp = Prf.discrete_FT(pulse_recentered)\n",
    "    \n",
    "    ## Create a plot and store the signal template in f-space\n",
    "    if j == 0:\n",
    "        plt.figure(title_1)\n",
    "        plt.plot(f[f_plot],abs(s[f_plot]**2),zorder=-5*j+5,color='k',linewidth=3)\n",
    "        \n",
    "    ## Focus the plot already containing the signal template, draw the average pulse for this file\n",
    "    plt.figure(title_1)\n",
    "    plt.plot(f[f_plot],abs(s_temp[f_plot]**2),zorder=-5*j+5,color=color)\n",
    "\n",
    "    ## Determine how many samples to shift the window when calculating J\n",
    "    samples_per_pulse  = sampling_rate*time_btw_pulse\n",
    "    window_shift_J_idx = int(window_shift_J*sampling_rate)\n",
    "    \n",
    "    ## Create a container to store J in temporarily\n",
    "    J_temp = np.zeros(N)\n",
    "    \n",
    "    ## Count how many good pulses there are in this file\n",
    "    n_good_pulses = num_pulses - len(bad_pls_idxs[pulse_file])\n",
    "\n",
    "    ## Loop over all the pulse windows in the file\n",
    "    ## Do we want to skip the windows cut out when finding average pulse? probably\n",
    "    k = 0\n",
    "    for pulse_i in range(pulse_start,int(total_pulses),1):\n",
    "        \n",
    "        ## Skip the bad pulse windows\n",
    "        if k in bad_pls_idxs[pulse_file]:\n",
    "            ## Increment the counter\n",
    "            k += 1\n",
    "            continue\n",
    "        \n",
    "        ## Find the index for the end of this pulse window\n",
    "        pulse_i_end = int((pulse_i+1)*samples_per_pulse) \n",
    "        \n",
    "        ## Apply the window shift and an array of samples for the window timestream points\n",
    "        ## Are we really trying to find a pulse free region? seems like it\n",
    "        no_pulse_idx_start = pulse_i_end + window_shift_J_idx - N\n",
    "        no_pulse_idx_end   = pulse_i_end + window_shift_J_idx\n",
    "        no_pulse_idx_list  = np.arange(no_pulse_idx_start,no_pulse_idx_end,1,dtype=int)\n",
    "        no_pulse_noise_i   = pulse_noise[no_pulse_idx_list]\n",
    "        \n",
    "        ## Caclulate the average J for thid region\n",
    "        J_temp += abs(Prf.discrete_FT(no_pulse_noise_i))**2 / n_good_pulses * 2 * T\n",
    "        # J_temp += abs(fft.ifft(no_pulse_noise_i))**2 / num_pulses * 2 * T\n",
    "        \n",
    "        ## Increment the counter\n",
    "        k += 1\n",
    "        \n",
    "    ## Plot the average J for this pulse file\n",
    "    plt.figure(title_2)\n",
    "    plt.plot(f[f_plot],J_temp[f_plot],zorder=-5*j+5,color=color)\n",
    "    plt.plot(f[f_plot],J[f_plot],zorder=-5*j+5,color=\"k\")\n",
    "    \n",
    "    plt.figure(title_2p2)\n",
    "    plt.scatter(Voltages[::-1][j],J_temp[f_plot][0],zorder=-5*j+5,color=color)\n",
    "    J_at_min_f = np.append(J_at_min_f, J_temp[f_plot][0])\n",
    "\n",
    "    ## Create containers for our output related to pulse height\n",
    "    ## One entry for every pulse window, not using cuts on baseline\n",
    "    A_hat     = np.zeros((n_good_pulses,N_mask))\n",
    "    A_max_idx = np.zeros(n_good_pulses)\n",
    "    A_hat_max = np.zeros(n_good_pulses)\n",
    "    A_hat_sum = np.zeros(n_good_pulses)\n",
    "    \n",
    "    ## Not sure that we want to apply an offset because of how we did things earlier?\n",
    "    ## We want the rising edge of the pulse centered\n",
    "    t_offset_idx = 0 # t_offset(N_mask) # \n",
    "    \n",
    "    ## Initialize a counter and loop over every pulse window\n",
    "    ## Again, do we want to skip the regions we cut earlier? probably not\n",
    "    k = 0 ; jj = 0\n",
    "    for pulse_i in range(pulse_start,int(total_pulses),1):\n",
    "        \n",
    "        ## Skip the bad pulse windows\n",
    "        if k in bad_pls_idxs[pulse_file]:\n",
    "            ## Increment the counter\n",
    "            k += 1\n",
    "            continue\n",
    "        \n",
    "        ## Apply the window shift and an array of samples for the window timestream points\n",
    "        ## This is the same window shift defined in the pulse averaging code block\n",
    "        pulse_i_start   = int(pulse_i*samples_per_pulse)\n",
    "        pulse_idx_start = pulse_i_start + window_shift\n",
    "        pulse_idx_end   = pulse_idx_start + N\n",
    "        pulse_idx_list  = np.arange(pulse_idx_start,pulse_idx_end,1,dtype=int)\n",
    "        pulse_noise_i   = pulse_noise[pulse_idx_list]\n",
    "\n",
    "        ## Fourier transform the baseline-subtracted window\n",
    "        v = Prf.discrete_FT(pulse_noise_i - np.mean(pulse_noise_i[:20])) \n",
    "        \n",
    "        ## Apply the window shift and an array of samples for the window timestream points\n",
    "        ## for the pulse free region\n",
    "        pulse_i_end        = int((pulse_i+1)*samples_per_pulse) \n",
    "        no_pulse_idx_start = pulse_i_end + window_shift_J_idx - N \n",
    "        no_pulse_idx_end   = pulse_i_end + window_shift_J_idx\n",
    "        no_pulse_idx_list  = np.arange(no_pulse_idx_start,no_pulse_idx_end,1,dtype=int)\n",
    "        no_pulse_noise_i   = pulse_noise[no_pulse_idx_list]\n",
    "        \n",
    "        ## Fourier transform the baseline-subtracted pulse-free window\n",
    "        v_temp = Prf.discrete_FT(no_pulse_noise_i)\n",
    "\n",
    "        ## Plot some number of pulses in the template pulse file\n",
    "        if j == 0 and (pulse_i + 0) % 20 == 0:\n",
    "            plt.figure(title_2p1)\n",
    "            plt.plot(time*1e3,pulse_noise_i,alpha=0.3)#color='k')\n",
    "\n",
    "        ## Calculate the numerator of the optimal filter \n",
    "        numerator = Prf.discrete_IFT(np.conj(s[f_mask])*v[f_mask]/J[f_mask])\n",
    "        numerator = numerator.real\n",
    "\n",
    "        ## Calculate the sum in the numerator of the optimal filter\n",
    "        numerator_sum = sum(offset_exponent[:,t_offset_idx]*np.conj(s[f_mask])*v_temp[f_mask]/J[f_mask])\n",
    "        numerator_sum = numerator_sum.real\n",
    "      \n",
    "        ## Find the maximum of the optimal filter numerator\n",
    "        max_numerator = max(numerator)\n",
    "        max_idx = np.argwhere(numerator == max_numerator)\n",
    "\n",
    "        ## Calculate the optimal filter\n",
    "        A_max_idx[jj] = max_idx \n",
    "        A_hat[jj,:]   = numerator / denominator\n",
    "        A_hat_max[jj] = max_numerator/ denominator\n",
    "        A_hat_sum[jj] = numerator_sum / denominator\n",
    "        \n",
    "        ## Increment the counter\n",
    "        k += 1 ; jj += 1\n",
    "        \n",
    "    ## Loop over the points in the mask and fit the OF to a gaussian, extracting the mean and sigma\n",
    "    for fp in range(N_mask):\n",
    "        (mu[fp], sigma[fp]) = norm.fit(A_hat[:,fp])\n",
    "    \n",
    "    ## If we are on the template file define the optimal t0 for the pulse\n",
    "    if j == 0:\n",
    "        optimal_t0 = t_offset_idx\n",
    "        \n",
    "    ## fit the OF max and sum to a gaussian, extracting the mean and sigma\n",
    "    (mu_max, sigma_max) = norm.fit(A_hat_max)\n",
    "    (mu_sum, sigma_sum) = norm.fit(A_hat_sum)\n",
    "    \n",
    "    ## Print the mean and sigma from the OF fit\n",
    "    print('mu = ' + \"{:.2e}\".format(mu[t_offset_idx]) + '; sigma = ' + \"{:.2e}\".format(sigma[t_offset_idx])+ '; sigma_0 = ' + \"{:.3e}\".format(b7_res))         \n",
    "\n",
    "    ## Draw the histograms of maximum amplitude index in the FFT spectra\n",
    "    plt.figure(title_2p5)\n",
    "    n, bins, patches = plt.hist(A_max_idx,bins=N,fill=False,histtype='step',label='radians',color=color)\n",
    "        \n",
    "    if (j+0) % 1 == 0: # True: # \n",
    "        # print(LED_files[j])\n",
    "        \n",
    "        ## Get the current array of optimal pulse heights\n",
    "        data = A_hat[:,optimal_t0]\n",
    "        nbins = 100\n",
    "        \n",
    "        ## Create the histograms of pulse heights and draw fits\n",
    "        plt.figure(title_3)\n",
    "        if j == 0:\n",
    "            n, bins, patches = plt.hist(data,bins=nbins,fill=False,histtype='step',label='radians',color=color,density=1.0)\n",
    "            bin_width = bins[1]-bins[0]\n",
    "        else:\n",
    "            n, bins, patches = plt.hist(data,bins=np.arange(min(data), max(data) + bin_width, bin_width),fill=False,histtype='step',label='radians',color=color,density=1.0)\n",
    "            \n",
    "        plt.plot(np.linspace(bins[0],bins[-1],100),\\\n",
    "                 norm.pdf(np.linspace(bins[0],bins[-1],100),mu[optimal_t0],sigma[optimal_t0]),\\\n",
    "                 c='gray')\n",
    "        \n",
    "        ## Manipulate the data to compare CDFs\n",
    "        data_sorted = np.sort(data)[2:-2]\n",
    "        xdata = data_sorted - np.min(data_sorted)\n",
    "        xdata = xdata/np.max(xdata)\n",
    "        ydata = np.cumsum(xdata)/np.sum(xdata)\n",
    "        \n",
    "        ## Create the CDF plots\n",
    "        plt.figure(title_3p5)\n",
    "        plt.step(xdata,ydata,where='post',color=color)\n",
    "\n",
    "    ## Write the fit results to the containers\n",
    "    mus.append(mu[optimal_t0]); sigmas.append(sigma[optimal_t0])\n",
    "\n",
    "    plt.figure(title_4)\n",
    "    if j == 0:\n",
    "        label1 = 'triggering on signal'\n",
    "        label2 = 'triggering on noise'\n",
    "    else:\n",
    "        label1 = None\n",
    "        label2 = None\n",
    "    plt.plot(mu[optimal_t0],sigma[optimal_t0],color=color,ls='',marker='s',label=label1)\n",
    "    plt.plot(mu_sum,        sigma_sum,        color=color,ls='',marker='s',label=label2,markersize=4,markeredgecolor='k')\n",
    "\n",
    "    ## Increment the counter for pulse files\n",
    "    j += 1\n",
    "\n",
    "## Format the plots\n",
    "plt.figure(title_1)\n",
    "ax = plt.gca(); ax.set_yscale('log'); ax.set_xscale('log')\n",
    "plt.title(title_1)\n",
    "\n",
    "plt.figure(title_2)\n",
    "ax = plt.gca(); ax.set_yscale('log'); ax.set_xscale('log')\n",
    "J_avg = np.mean(J)\n",
    "plt.ylim([1e-1*J_avg,1e2*J_avg])\n",
    "plt.title(title_2)\n",
    "\n",
    "plt.figure(title_2p1)\n",
    "plt.title(title_2p1)\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "\n",
    "plt.figure(title_2p2)\n",
    "plt.title(title_2p2)\n",
    "plt.xlabel(\"LED Voltage [V]\")\n",
    "plt.ylabel(r\"$J(f=f_\\mathrm{min})$\")\n",
    "\n",
    "line = lambda x, m, b: m*x + b\n",
    "min_fit_idx = 0\n",
    "\n",
    "xdata = Voltages[::-1]#[:-min_fit_idx]\n",
    "ydata = J_at_min_f#[:-min_fit_idx]\n",
    "print(xdata)\n",
    "print(ydata)\n",
    "popt, pcov = curve_fit( line , xdata, ydata, p0=[0.4e-19, -0.4e-19] )\n",
    "plt.plot(Voltages, line(Voltages,popt[0],popt[1]), 'k-',label=\"Slope: \"+str(popt[0]))\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.figure(title_2p5)\n",
    "plt.title(title_2p5)\n",
    "plt.xlabel(r'index of IFFT($\\frac{s^*v}{J}$)')\n",
    "\n",
    "plt.figure(title_3)\n",
    "plt.title(title_3)\n",
    "plt.xlabel('pulse heights normalized to tallest pulse')\n",
    "plt.ylabel('density of pulses')\n",
    "if True:\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.gca().set_yscale('log')\n",
    "    plt.gca().set_ylim([1e-1,ylim[1]])\n",
    "\n",
    "plt.figure(title_3p5)\n",
    "plt.title(title_3p5)\n",
    "plt.xlabel('normalized pulse height range')\n",
    "plt.ylabel('cumulative distribution')\n",
    "plt.gca().set_ylim([-0.1,1.1])\n",
    "\n",
    "plt.figure(title_4)\n",
    "plt.title(title_4)\n",
    "plt.axhline(b7_res,color='grey',label='baseline resolution')\n",
    "plt.xlabel('pulse height normalized to tallest pulse',fontsize=18)\n",
    "plt.ylabel('$\\sigma$',fontsize=18)\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "print(sigma.shape)\n",
    "for j in range(N_mask):\n",
    "    plt.plot(np.mean(sigma,axis=0))\n",
    "    plt.plot(optimal_t0,np.mean(sigma[optimal_t0]),ls='',marker='.',color='k')\n",
    "plt.xlabel('time offset')\n",
    "plt.ylabel('OF noise')\n",
    "plt.title('triggering on noise before pulse')\n",
    "\n",
    "def sig(mu,sigma_0,r):\n",
    "#     return np.sqrt(sigma_0**2 + (mu)*r)\n",
    "    return np.sqrt(b7_res**2 + (mu)*r)\n",
    "\n",
    "def sig2(mu,r):\n",
    "    return np.sqrt(b7_res**2 + (mu)*r)\n",
    "\n",
    "\n",
    "mus = np.array(mus)\n",
    "sigmas = np.array(sigmas)\n",
    "\n",
    "p0 = [1e-1,1e-2]\n",
    "# f_fit_vals,_ = curve_fit(f,mu,sigma,p0,bounds=[(15*(0.008/2.6),7e-3),(40*(0.008/2.6),0.1)])\n",
    "# f_fit_vals,_ = curve_fit(sig,mus[sigmas<0.035],sigmas[sigmas<0.035],p0)\n",
    "f_fit_vals,_ = curve_fit(sig,mus,sigmas,p0)\n",
    "print(np.max(sigma))\n",
    "# f_fit_vals,_ = curve_fit(sig2,mu,[p0[1]])\n",
    "\n",
    "# sigma_0_E_pub = abs(f_fit_vals[0])/(f_fit_vals[1]/2.6)\n",
    "sigma_0_E_pub = abs(b7_res)/(f_fit_vals[1]/2.6)\n",
    "# r_E = f_fit_vals[0]/2.6\n",
    "r_E = f_fit_vals[1]/2.6\n",
    "print(r_E)\n",
    "print('energy resolution estimate is: ' + str(sigma_0_E_pub))\n",
    "\n",
    "mu_plot = np.linspace(0,1.25,100)\n",
    "plt.figure(title_4)\n",
    "plt.plot(mus,np.array(sigmas))\n",
    "plt.plot(mu_plot,sig(mu_plot,*f_fit_vals),label='$\\sigma_0$='+str(round(sigma_0_E_pub,1))+'eV')\n",
    "plt.legend(loc='best',fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sigma_vs_mu.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MB_equations as MBe\n",
    "T = 10.0e-3       ; print(T) ## K\n",
    "f = readout_f     ; print(f) ## MHz\n",
    "D = MB_fit_vals[1]; print(D) ## meV\n",
    "k2 = MBe.kappa_2(T, f*1e6, D*1e-3) *1e6*1e6*1e6\n",
    "print(k2, \"um^-3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
